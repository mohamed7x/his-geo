{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tce3stUlHN0L"
      },
      "source": [
        "##### Copyright 2024 Google LLC."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "tuOe1ymfHZPu"
      },
      "outputs": [],
      "source": [
        "# @title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yeadDkMiISin"
      },
      "source": [
        "# Gemini API: Prompting Quickstart\n",
        "\n",
        "<table align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/google-gemini/cookbook/blob/main/quickstarts/Prompting.ipynb\"><img src=\"https://github.com/google-gemini/cookbook/blob/main/images/colab_logo_32px.png?raw=1\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dpOYALec6N8Z"
      },
      "source": [
        "This notebook contains examples of how to write and run your first prompts with the Gemini API."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "0c13de5f68f6"
      },
      "outputs": [],
      "source": [
        "!pip install -U -q \"google-generativeai>=0.7.2\" # Install the Python SDK"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "TS9l5igubpHO"
      },
      "outputs": [],
      "source": [
        "import google.generativeai as genai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w4YDYyfRYN7L"
      },
      "source": [
        "## Set up your API key\n",
        "\n",
        "To run the following cell, your API key must be stored it in a Colab Secret named `GOOGLE_API_KEY`. If you don't already have an API key, or you're not sure how to create a Colab Secret, see the [Authentication](https://github.com/google-gemini/cookbook/blob/main/quickstarts/Authentication.ipynb) quickstart for an example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "p8K1RpmMfh20"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\n",
        "genai.configure(api_key=GOOGLE_API_KEY)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HTNQymX8YN9c"
      },
      "source": [
        "## Run your first prompt\n",
        "\n",
        "Use the `generate_content` method to generate responses to your prompts. You can pass text directly to generate_content, and use the `.text` property to get the text content of the response."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "XSuyaGmcf6sr",
        "outputId": "8b2f53a1-f120-457a-827e-7de191bf6537",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python offers several ways to sort a list. Here are a few examples, demonstrating different approaches and use cases:\n",
            "\n",
            "**1. Using the `list.sort()` method (in-place sorting):**\n",
            "\n",
            "This method modifies the original list directly.  It's efficient for large lists because it doesn't create a copy.\n",
            "\n",
            "```python\n",
            "my_list = [3, 1, 4, 1, 5, 9, 2, 6]\n",
            "my_list.sort()  # Sorts in ascending order by default\n",
            "print(my_list)  # Output: [1, 1, 2, 3, 4, 5, 6, 9]\n",
            "\n",
            "my_list.sort(reverse=True)  # Sorts in descending order\n",
            "print(my_list)  # Output: [9, 6, 5, 4, 3, 2, 1, 1]\n",
            "```\n",
            "\n",
            "**2. Using the `sorted()` function (creates a new sorted list):**\n",
            "\n",
            "This function returns a *new* sorted list, leaving the original list unchanged.  This is useful when you need to preserve the original list.\n",
            "\n",
            "```python\n",
            "my_list = [3, 1, 4, 1, 5, 9, 2, 6]\n",
            "sorted_list = sorted(my_list)\n",
            "print(my_list)      # Output: [3, 1, 4, 1, 5, 9, 2, 6] (original list unchanged)\n",
            "print(sorted_list)  # Output: [1, 1, 2, 3, 4, 5, 6, 9] (new sorted list)\n",
            "\n",
            "sorted_list_desc = sorted(my_list, reverse=True)\n",
            "print(sorted_list_desc) # Output: [9, 6, 5, 4, 3, 2, 1, 1]\n",
            "```\n",
            "\n",
            "**3. Sorting with a custom key (for more complex sorting):**\n",
            "\n",
            "If you need to sort based on a specific attribute or criteria of the list elements (e.g., sorting a list of objects by a particular attribute), you can use a `key` function.\n",
            "\n",
            "```python\n",
            "data = [('apple', 5), ('banana', 2), ('cherry', 8)]\n",
            "\n",
            "# Sort by the second element (the number) in ascending order\n",
            "sorted_data = sorted(data, key=lambda item: item[1])\n",
            "print(sorted_data)  # Output: [('banana', 2), ('apple', 5), ('cherry', 8)]\n",
            "\n",
            "#Sort by the first element (the fruit name) in descending order\n",
            "sorted_data_desc = sorted(data, key=lambda item: item[0], reverse=True)\n",
            "print(sorted_data_desc) # Output: [('cherry', 8), ('banana', 2), ('apple', 5)]\n",
            "\n",
            "class Person:\n",
            "    def __init__(self, name, age):\n",
            "        self.name = name\n",
            "        self.age = age\n",
            "\n",
            "people = [Person(\"Alice\", 30), Person(\"Bob\", 25), Person(\"Charlie\", 35)]\n",
            "\n",
            "# Sort people by age\n",
            "sorted_people = sorted(people, key=lambda person: person.age)\n",
            "print([p.name for p in sorted_people]) # Output: ['Bob', 'Alice', 'Charlie']\n",
            "```\n",
            "\n",
            "Remember to choose the method that best suits your needs.  `list.sort()` is generally faster for in-place sorting of large lists, while `sorted()` is more convenient when you need to keep the original list intact.  The `key` argument provides powerful flexibility for complex sorting scenarios.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "model = genai.GenerativeModel('gemini-1.5-flash')\n",
        "response = model.generate_content(\"Give me python code to sort a list\")\n",
        "print(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XE-6e7gePN7Q"
      },
      "source": [
        "## Have a chat\n",
        "\n",
        "The Gemini API enables you to have freeform conversations across multiple turns.\n",
        "\n",
        "The [ChatSession](https://ai.google.dev/api/python/google/generativeai/ChatSession) class will store the conversation history for multi-turn interactions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZKAtY5oIPQW0"
      },
      "outputs": [],
      "source": [
        "model = genai.GenerativeModel('gemini-1.5-flash')\n",
        "chat = model.start_chat(history=[])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9tXNVnqxPcXy",
        "outputId": "44c225b7-7361-411a-988e-017f7737701f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "A computer is like a super smart toy that follows instructions from you, using numbers and lights to do amazing things! \n",
            "\n"
          ]
        }
      ],
      "source": [
        "response = chat.send_message(\"In one sentence, explain how a computer works to a young child.\")\n",
        "print(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7TChH2l5PhFf"
      },
      "source": [
        "You can see the chat history:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dHwrC82YPiWS",
        "outputId": "78cfee6d-27a7-4ff8-85be-c1b4011b6747"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[parts {\n",
            "  text: \"In one sentence, explain how a computer works to a young child.\"\n",
            "}\n",
            "role: \"user\"\n",
            ", parts {\n",
            "  text: \"A computer is like a super smart toy that follows instructions from you, using numbers and lights to do amazing things! \\n\"\n",
            "}\n",
            "role: \"model\"\n",
            "]\n"
          ]
        }
      ],
      "source": [
        "print(chat.history)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EvHvt1OEPl7D"
      },
      "source": [
        "You can keep sending messages to continue the conversation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-fXZZQPzPkie"
      },
      "outputs": [],
      "source": [
        "response = chat.send_message(\"Okay, how about a more detailed explanation to a high schooler?\")\n",
        "print(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65476e75ece0"
      },
      "source": [
        "## Set the temperature"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "56f68c900144"
      },
      "source": [
        "Every prompt you send to the model includes parameters that control how the model generates responses. Use a `genai.GenerationConfig` to set these, or omit it to use the defaults.\n",
        "\n",
        "Temperature controls the degree of randomness in token selection. Use higher values for more creative responses, and lower values for more deterministic responses.\n",
        "\n",
        "You can set the `generation_config` when creating the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "28477e706226"
      },
      "outputs": [],
      "source": [
        "model = genai.GenerativeModel(\n",
        "    'gemini-1.5-flash',\n",
        "    generation_config=genai.GenerationConfig(\n",
        "        max_output_tokens=2000,\n",
        "        temperature=0.6,\n",
        "    ))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e3c68071ed8b"
      },
      "source": [
        "Or, set the `generation_config` on an individual call to `generate_content`. Any values set there override values on the model constructor.\n",
        "\n",
        "Note: Although you can set the `candidate_count` in the generation_config, gemini-pro models will only return a single candidate at the this time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f895c7f55b30"
      },
      "outputs": [],
      "source": [
        "response = model.generate_content(\n",
        "    'Give me a numbered list of cat facts.',\n",
        "    # Limit to 5 facts.\n",
        "    generation_config = genai.GenerationConfig(stop_sequences=['\\n6'])\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c97c16e6a961"
      },
      "outputs": [],
      "source": [
        "print(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gvkDhXtHgol7"
      },
      "source": [
        "## Learn more\n",
        "\n",
        "There's lots more to learn!\n",
        "\n",
        "* For more fun prompts, check out [Market a Jetpack](https://github.com/google-gemini/cookbook/blob/main/examples/Market_a_Jet_Backpack.ipynb).\n",
        "* Check out the [safety quickstart](https://github.com/google-gemini/cookbook/blob/main/quickstarts/Safety.ipynb) next to learn about the Gemini API's configurable safety settings, and what to do if your prompt is blocked.\n",
        "* For lots more details on using the Python SDK, check out this [detailed quickstart](https://ai.google.dev/tutorials/python_quickstart)."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Prompting.ipynb",
      "toc_visible": true,
      "provenance": []
    },
    "google": {
      "image_path": "/static/site-assets/images/docs/logo-python.svg",
      "keywords": [
        "examples",
        "gemini",
        "beginner",
        "googleai",
        "quickstart",
        "python",
        "text",
        "chat",
        "vision",
        "embed"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}